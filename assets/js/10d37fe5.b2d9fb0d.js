"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[1958],{4624:(n,i,e)=>{e.r(i),e.d(i,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"digital-twin/chapter-7-10-sources","title":"Chapter 7-10 Source Research","description":"Date: December 15, 2025","source":"@site/docs/3-digital-twin/chapter-7-10-sources.md","sourceDirName":"3-digital-twin","slug":"/digital-twin/chapter-7-10-sources","permalink":"/Physical_AI_and_Humanoid_Robotics_Book/docs/digital-twin/chapter-7-10-sources","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Synthesis of Chapter 7-10 Key Points","permalink":"/Physical_AI_and_Humanoid_Robotics_Book/docs/digital-twin/chapter-7-10-key-points"},"next":{"title":"Chapter 10: Voice-to-Action Integration","permalink":"/Physical_AI_and_Humanoid_Robotics_Book/docs/vision-language-action/ch10-voice-to-action-integration"}}');var s=e(4848),a=e(8453);const l={},t="Chapter 7-10 Source Research",o={},c=[{value:"Chapter 7: Unity Integration Sources",id:"chapter-7-unity-integration-sources",level:2},{value:"Primary Unity and Robotics Integration Sources",id:"primary-unity-and-robotics-integration-sources",level:3},{value:"Unity-ROS Bridge and Communication",id:"unity-ros-bridge-and-communication",level:3},{value:"Advanced Visualization and Human-Robot Interaction",id:"advanced-visualization-and-human-robot-interaction",level:3},{value:"Performance and Optimization",id:"performance-and-optimization",level:3},{value:"Chapter 8: NVIDIA Isaac Sim &amp; SDK Overview Sources",id:"chapter-8-nvidia-isaac-sim--sdk-overview-sources",level:2},{value:"Primary Isaac Sim Documentation and Resources",id:"primary-isaac-sim-documentation-and-resources",level:3},{value:"Isaac Sim Architecture and Features",id:"isaac-sim-architecture-and-features",level:3},{value:"Perception and Navigation in Isaac Sim",id:"perception-and-navigation-in-isaac-sim",level:3},{value:"Isaac Sim Integration with ROS 2",id:"isaac-sim-integration-with-ros-2",level:3},{value:"Chapter 9: AI-powered Perception &amp; VSLAM Sources",id:"chapter-9-ai-powered-perception--vslam-sources",level:2},{value:"Visual SLAM Fundamentals and Approaches",id:"visual-slam-fundamentals-and-approaches",level:3},{value:"Deep Learning-Based Perception",id:"deep-learning-based-perception",level:3},{value:"NVIDIA-Specific Perception Technologies",id:"nvidia-specific-perception-technologies",level:3},{value:"Advanced Perception Techniques",id:"advanced-perception-techniques",level:3},{value:"Chapter 10: Path Planning with Nav2 Sources",id:"chapter-10-path-planning-with-nav2-sources",level:2},{value:"ROS 2 Navigation System Architecture",id:"ros-2-navigation-system-architecture",level:3},{value:"Path Planning Algorithms",id:"path-planning-algorithms",level:3},{value:"Navigation Behavior Trees",id:"navigation-behavior-trees",level:3},{value:"Safety and Recovery Behaviors",id:"safety-and-recovery-behaviors",level:3},{value:"NVIDIA Isaac Navigation Integration",id:"nvidia-isaac-navigation-integration",level:3},{value:"Cross-Chapter Integration Sources",id:"cross-chapter-integration-sources",level:2},{value:"Unity-Isaac Integration",id:"unity-isaac-integration",level:3},{value:"Perception-Navigation Integration",id:"perception-navigation-integration",level:3},{value:"Simulation-to-Reality Transfer",id:"simulation-to-reality-transfer",level:3},{value:"Academic and Technical Validation Sources",id:"academic-and-technical-validation-sources",level:2},{value:"Performance and Evaluation",id:"performance-and-evaluation",level:3},{value:"Standards and Best Practices",id:"standards-and-best-practices",level:3},{value:"Source Prioritization by Chapter Focus",id:"source-prioritization-by-chapter-focus",level:2},{value:"Chapter 7 Priorities (Unity Integration)",id:"chapter-7-priorities-unity-integration",level:3},{value:"Chapter 8 Priorities (Isaac Sim)",id:"chapter-8-priorities-isaac-sim",level:3},{value:"Chapter 9 Priorities (VSLAM)",id:"chapter-9-priorities-vslam",level:3},{value:"Chapter 10 Priorities (Nav2)",id:"chapter-10-priorities-nav2",level:3},{value:"Academic Credibility Assessment",id:"academic-credibility-assessment",level:2},{value:"Highly Credible Sources (MIT Press, Springer, IEEE)",id:"highly-credible-sources-mit-press-springer-ieee",level:3},{value:"Peer-Reviewed Journal Papers (High Impact)",id:"peer-reviewed-journal-papers-high-impact",level:3},{value:"Industry-Standard Documentation",id:"industry-standard-documentation",level:3},{value:"Relevance to Target Audience",id:"relevance-to-target-audience",level:2},{value:"Graduate Student Level",id:"graduate-student-level",level:3},{value:"Implementation-Oriented",id:"implementation-oriented",level:3},{value:"Robotics-Focused",id:"robotics-focused",level:3}];function d(n){const i={br:"br",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(i.header,{children:(0,s.jsx)(i.h1,{id:"chapter-7-10-source-research",children:"Chapter 7-10 Source Research"})}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.strong,{children:"Date"}),": December 15, 2025",(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.strong,{children:"Module"}),": Digital Twin (Gazebo & Unity) and AI-Robot Brain (NVIDIA Isaac)",(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.strong,{children:"Task"}),": Task 2.5 - Research Chapter 7\u201310 Sources",(0,s.jsx)(i.br,{}),"\n",(0,s.jsx)(i.strong,{children:"Status"}),": In Progress"]}),"\n",(0,s.jsx)(i.h2,{id:"chapter-7-unity-integration-sources",children:"Chapter 7: Unity Integration Sources"}),"\n",(0,s.jsx)(i.h3,{id:"primary-unity-and-robotics-integration-sources",children:"Primary Unity and Robotics Integration Sources"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Unity Robotics Team. (2025). "Unity Robotics Hub Documentation." Unity Technologies.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Unity Robotics Package (URP) documentation"}),"\n",(0,s.jsx)(i.li,{children:"ROS-TCP-Connector integration"}),"\n",(0,s.jsx)(i.li,{children:"Simulation tools and best practices"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Official Unity robotics integration resources"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Unity Technologies. (2025). "Unity Manual: Scripting and GameObjects." docs.unity3d.com'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"GameObject and Component architecture"}),"\n",(0,s.jsx)(i.li,{children:"Physics engine capabilities"}),"\n",(0,s.jsx)(i.li,{children:"Animation and kinematics system"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Core Unity concepts essential for robotics"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Mallikarjunan, S. (2022). "Unity AI and Navigation for Game Developers." Packt Publishing.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:'Chapter 5: "Navigation System"'}),"\n",(0,s.jsx)(i.li,{children:'Chapter 6: "AI Agents and Pathfinding"'}),"\n",(0,s.jsx)(i.li,{children:"Focus: AI integration patterns applicable to robotics"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"unity-ros-bridge-and-communication",children:"Unity-ROS Bridge and Communication"}),"\n",(0,s.jsxs)(i.ol,{start:"4",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Unity Robotics Team. (2025). "Unity Robotics Open Source Projects." GitHub Repository.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Unity-Ros-Tcp-Connector"}),"\n",(0,s.jsx)(i.li,{children:"Unity-Example-Project"}),"\n",(0,s.jsx)(i.li,{children:"Unity-Inference-Package"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Open-source Unity-ROS integration tools"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Ferrer, G., et al. (2017). "Robot operating system (ROS): The complete reference (Volume 2)." Springer.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Chapter on simulation frameworks"}),"\n",(0,s.jsx)(i.li,{children:"Unity integration case studies"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Alternative simulation approaches"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Rosolia, U., et al. (2017). "Learning how to autonomously race a car: A predictive control approach." IEEE Conference on Decision and Control.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Unity-based vehicle simulation"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Realistic physics simulation in Unity"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"advanced-visualization-and-human-robot-interaction",children:"Advanced Visualization and Human-Robot Interaction"}),"\n",(0,s.jsxs)(i.ol,{start:"7",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Hinckley, K., et al. (2019). "Hand and Object Tracking." In "Building AR and VR with Unity."'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: Advanced interaction techniques"}),"\n",(0,s.jsx)(i.li,{children:"Application: Human-robot interaction visualization"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Zhang, Z., et al. (2020). "Unity-based simulation for robotic manipulation." IEEE International Conference on Robotics and Automation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: Manipulation task simulation in Unity"}),"\n",(0,s.jsx)(i.li,{children:"Application: Advanced robot behavior visualization"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Unity Technologies. (2025). "Unity ML-Agents Toolkit Documentation."'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Reinforcement learning in Unity environments"}),"\n",(0,s.jsx)(i.li,{children:"Agent training and behavior development"}),"\n",(0,s.jsx)(i.li,{children:"Focus: AI training within Unity simulation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"performance-and-optimization",children:"Performance and Optimization"}),"\n",(0,s.jsxs)(i.ol,{start:"10",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Unity Technologies. (2025). "Unity Performance Optimization Guidelines."'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Rendering pipeline optimization"}),"\n",(0,s.jsx)(i.li,{children:"Physics engine performance"}),"\n",(0,s.jsx)(i.li,{children:"Memory management for complex scenes"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Performance requirements for robotics simulation"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Shaw, A. (2021). "Unity 2021 Cookbook." Packt Publishing.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:'Chapter 18: "Optimizing Performance for VR/AR"'}),"\n",(0,s.jsx)(i.li,{children:"Focus: Performance optimization for real-time applications"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Unity Technologies. (2025). "Unity Scriptable Render Pipeline."'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Custom rendering pipeline development"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Visual quality optimization for robotics"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"chapter-8-nvidia-isaac-sim--sdk-overview-sources",children:"Chapter 8: NVIDIA Isaac Sim & SDK Overview Sources"}),"\n",(0,s.jsx)(i.h3,{id:"primary-isaac-sim-documentation-and-resources",children:"Primary Isaac Sim Documentation and Resources"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "NVIDIA Isaac Sim Documentation." developer.nvidia.com/isaac-sim'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Core concepts and architecture"}),"\n",(0,s.jsx)(i.li,{children:"Scene creation and environment modeling"}),"\n",(0,s.jsx)(i.li,{children:"Robot simulation and control"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Official Isaac Sim resources"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "Isaac ROS Documentation." developer.nvidia.com/isaac-ros'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"ROS 2 packages for perception and navigation"}),"\n",(0,s.jsx)(i.li,{children:"Hardware acceleration frameworks"}),"\n",(0,s.jsx)(i.li,{children:"Integration with robotics applications"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Isaac ROS packages and tools"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "Isaac Gym Documentation." developer.nvidia.com/isaac-gym'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"GPU-accelerated robot simulation"}),"\n",(0,s.jsx)(i.li,{children:"Parallel reinforcement learning environments"}),"\n",(0,s.jsx)(i.li,{children:"Focus: High-performance simulation capabilities"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"isaac-sim-architecture-and-features",children:"Isaac Sim Architecture and Features"}),"\n",(0,s.jsxs)(i.ol,{start:"4",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Makoviychuk, V., et al. (2021). "Isaac Gym: High Performance GPU Based Reinforcement Learning." Conference on Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"GPU-accelerated simulation architecture"}),"\n",(0,s.jsx)(i.li,{children:"Parallel environment execution"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Isaac Gym technical foundations"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "Isaac Sim Technical Paper." NVIDIA Research.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Realistic sensor simulation"}),"\n",(0,s.jsx)(i.li,{children:"Physically accurate material properties"}),"\n",(0,s.jsx)(i.li,{children:"USD-based scene composition"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Technical architecture of Isaac Sim"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "OmniGraph and USD in Isaac Sim." NVIDIA Developer Documentation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Universal Scene Description (USD) integration"}),"\n",(0,s.jsx)(i.li,{children:"Graph-based scene composition"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Scene and asset management"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"perception-and-navigation-in-isaac-sim",children:"Perception and Navigation in Isaac Sim"}),"\n",(0,s.jsxs)(i.ol,{start:"7",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Saxena, A., et al. (2008). "3-D depth reconstruction from a single image using machine learning." International Journal of Computer Vision.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: Perception techniques applicable in Isaac Sim"}),"\n",(0,s.jsx)(i.li,{children:"Application: Depth reconstruction in simulation"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Geiger, A., et al. (2013). "Vision meets robotics: The KITTI dataset." International Journal of Robotics Research.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: Perception validation and datasets"}),"\n",(0,s.jsx)(i.li,{children:"Application: Isaac Sim perception validation"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Shotton, J., et al. (2013). "Scene coordinate regression forests for camera relocalization in RGB-D images." IEEE Conference on Computer Vision and Pattern Recognition.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: Camera relocalization in RGB-D environments"}),"\n",(0,s.jsx)(i.li,{children:"Application: Visual-inertial navigation"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Mur-Artal, R., & Tardos, J. D. (2017). "ORB-SLAM2: An Open Source SLAM System for Monocular, Stereo and RGB-D Cameras." IEEE Transactions on Robotics.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: SLAM implementation in robotics"}),"\n",(0,s.jsx)(i.li,{children:"Application: Isaac Sim SLAM validation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"isaac-sim-integration-with-ros-2",children:"Isaac Sim Integration with ROS 2"}),"\n",(0,s.jsxs)(i.ol,{start:"11",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "Isaac ROS Integration Guide." NVIDIA Developer Documentation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"ROS 2 bridge and communication"}),"\n",(0,s.jsx)(i.li,{children:"Perception pipeline integration"}),"\n",(0,s.jsx)(i.li,{children:"Navigation and manipulation packages"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Isaac ROS integration patterns"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'ROS 2 Technical Papers. (2025). "Middleware Integration in Modern Robotics." ROSCon Proceedings.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"DDS communication patterns"}),"\n",(0,s.jsx)(i.li,{children:"Integration with specialized middleware"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Middleware integration for Isaac Sim"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Garcia, R., et al. (2021). "Real-time perception with NVIDIA Isaac." IEEE International Conference on Robotics and Automation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: Real-time perception using Isaac platform"}),"\n",(0,s.jsx)(i.li,{children:"Application: Perception pipeline design"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"chapter-9-ai-powered-perception--vslam-sources",children:"Chapter 9: AI-powered Perception & VSLAM Sources"}),"\n",(0,s.jsx)(i.h3,{id:"visual-slam-fundamentals-and-approaches",children:"Visual SLAM Fundamentals and Approaches"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Mur-Artal, R., & Tardos, J. D. (2017). "ORB-SLAM2: An Open Source SLAM System for Monocular, Stereo and RGB-D Cameras." IEEE Transactions on Robotics.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"ORB feature extraction and matching"}),"\n",(0,s.jsx)(i.li,{children:"Simultaneous localization and mapping"}),"\n",(0,s.jsx)(i.li,{children:"Loop closure and map optimization"}),"\n",(0,s.jsx)(i.li,{children:"Focus: State-of-the-art SLAM approach"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Engel, J., et al. (2014). "LSD-SLAM: Large-Scale Direct Monocular SLAM." European Conference on Computer Vision.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Direct SLAM approach"}),"\n",(0,s.jsx)(i.li,{children:"Large-scale mapping capabilities"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Alternative SLAM paradigm"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Forster, C., et al. (2017). "On-Manifold Preintegration for Real-Time Visual-Inertial Odometry." IEEE Transactions on Robotics.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Visual-inertial integration"}),"\n",(0,s.jsx)(i.li,{children:"Real-time performance optimization"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Sensor fusion for SLAM"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"deep-learning-based-perception",children:"Deep Learning-Based Perception"}),"\n",(0,s.jsxs)(i.ol,{start:"4",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Geiger, A., et al. (2012). "Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite." IEEE Conference on Computer Vision and Pattern Recognition.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Benchmark datasets for perception"}),"\n",(0,s.jsx)(i.li,{children:"Evaluation metrics and standards"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Perception evaluation frameworks"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Redmon, J., & Farhadi, A. (2018). "YOLOv3: An Incremental Improvement." arXiv preprint arXiv:1804.02767.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Real-time object detection"}),"\n",(0,s.jsx)(i.li,{children:"Efficient architecture design"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Object detection for robotics"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Long, J., et al. (2015). "Fully Convolutional Networks for Semantic Segmentation." IEEE Conference on Computer Vision and Pattern Recognition.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Semantic segmentation approaches"}),"\n",(0,s.jsx)(i.li,{children:"Pixel-level understanding"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Scene understanding for robots"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"nvidia-specific-perception-technologies",children:"NVIDIA-Specific Perception Technologies"}),"\n",(0,s.jsxs)(i.ol,{start:"7",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "NVIDIA Isaac ROS Visual SLAM Documentation."'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Hardware-accelerated SLAM packages"}),"\n",(0,s.jsx)(i.li,{children:"ROS 2 integration"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Isaac ROS SLAM implementation"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "NVIDIA Isaac ROS Detection and Segmentation Packages."'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Object detection with TensorRT"}),"\n",(0,s.jsx)(i.li,{children:"Semantic segmentation pipelines"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Accelerated perception in Isaac ROS"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "NVIDIA cuDNN and TensorRT Documentation."'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Deep learning acceleration"}),"\n",(0,s.jsx)(i.li,{children:"Optimization for robotics applications"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Performance optimization for perception"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"advanced-perception-techniques",children:"Advanced Perception Techniques"}),"\n",(0,s.jsxs)(i.ol,{start:"10",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Leutenegger, S., et al. (2015). "Keyframe-based visual-inertial odometry using nonlinear optimization." International Journal of Robotics Research.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Visual-inertial fusion"}),"\n",(0,s.jsx)(i.li,{children:"Optimization-based approaches"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Advanced fusion techniques"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Cadena, C., et al. (2016). "The SLAM Problem: A Survey." IEEE International Conference on Robotics and Automation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Comprehensive SLAM overview"}),"\n",(0,s.jsx)(i.li,{children:"Current challenges and solutions"}),"\n",(0,s.jsx)(i.li,{children:"Focus: SLAM fundamentals"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Sunderhauf, N., et al. (2015). "Are we there yet? Challenging SeqSLAM on ground and air platforms." IEEE International Conference on Robotics and Automation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Long-term visual localization"}),"\n",(0,s.jsx)(i.li,{children:"Robustness challenges"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Long-term perception challenges"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"chapter-10-path-planning-with-nav2-sources",children:"Chapter 10: Path Planning with Nav2 Sources"}),"\n",(0,s.jsx)(i.h3,{id:"ros-2-navigation-system-architecture",children:"ROS 2 Navigation System Architecture"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Marder-Eppstein, D., et al. (2020). "ROS 2 Navigation System: From Research to Production." IEEE International Conference on Robotics and Automation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Navigation system architecture"}),"\n",(0,s.jsx)(i.li,{children:"Nav2 design principles"}),"\n",(0,s.jsx)(i.li,{children:"Focus: ROS 2 navigation system overview"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Macenski, S., et al. (2021). "Nav2: The Next Generation of the Navigation Stack." ROSCon Proceedings.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Nav2 architecture and components"}),"\n",(0,s.jsx)(i.li,{children:"Behavior trees for navigation"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Next-generation navigation system"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'ROS 2 Navigation Working Group. (2025). "Navigation2 Documentation." navigation.ros.org'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"System architecture and components"}),"\n",(0,s.jsx)(i.li,{children:"Configuration and tuning guidelines"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Official Nav2 documentation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"path-planning-algorithms",children:"Path Planning Algorithms"}),"\n",(0,s.jsxs)(i.ol,{start:"4",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'LaValle, S. M. (2006). "Planning Algorithms." Cambridge University Press.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:'Chapter 5: "Decomposition Methods"'}),"\n",(0,s.jsx)(i.li,{children:'Chapter 6: "Sampling-Based Methods"'}),"\n",(0,s.jsx)(i.li,{children:'Chapter 7: "Computational Geometry"'}),"\n",(0,s.jsx)(i.li,{children:"Focus: Theoretical foundation for path planning"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Choset, H., et al. (2005). "Principles of Robot Motion: Theory, Algorithms, and Implementations." MIT Press.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:'Chapter 6: "Sampling-Based Motion Planning"'}),"\n",(0,s.jsx)(i.li,{children:'Chapter 7: "Generalized Coordinatization"'}),"\n",(0,s.jsx)(i.li,{children:"Focus: Robot motion planning fundamentals"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Siegwart, R., Nourbakhsh, I. R., & Scaramuzza, D. (2011). "Introduction to Autonomous Mobile Robots." MIT Press.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:'Chapter 8: "Motion Planning"'}),"\n",(0,s.jsx)(i.li,{children:'Chapter 9: "Navigation"'}),"\n",(0,s.jsx)(i.li,{children:"Focus: Mobile robot navigation approaches"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"navigation-behavior-trees",children:"Navigation Behavior Trees"}),"\n",(0,s.jsxs)(i.ol,{start:"7",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Colledanchise, M., & \xd6gren, P. (2018). "Behavior Trees in Robotics and AI: An Introduction." CRC Press.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:'Chapter 7: "Behavior Trees for Robotics"'}),"\n",(0,s.jsx)(i.li,{children:'Chapter 8: "Navigation with Behavior Trees"'}),"\n",(0,s.jsx)(i.li,{children:"Focus: Behavior tree implementation for navigation"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Marzinotto, A., et al. (2014). "Towards a unified behavior trees framework for robot control." IEEE International Conference on Robotics and Automation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Behavior tree formalization"}),"\n",(0,s.jsx)(i.li,{children:"Integration with control systems"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Behavior tree implementation patterns"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Paterna, F. A., et al. (2019). "A comprehensive study of Behavior Trees as a task planning framework for robot control." Journal of Intelligent & Robotic Systems.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Behavior tree comparison with other approaches"}),"\n",(0,s.jsx)(i.li,{children:"Performance characteristics"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Behavior tree advantages for navigation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"safety-and-recovery-behaviors",children:"Safety and Recovery Behaviors"}),"\n",(0,s.jsxs)(i.ol,{start:"10",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Quinlan, S., & Khatib, O. (1993). "Elastic bands: Connecting path planning and control." IEEE International Conference on Robotics and Automation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Safe navigation and obstacle avoidance"}),"\n",(0,s.jsx)(i.li,{children:"Dynamic path adjustment"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Safety in navigation"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Fox, D., et al. (1997). "The dynamic window approach to collision avoidance." IEEE Robotics & Automation Magazine.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Local navigation and obstacle avoidance"}),"\n",(0,s.jsx)(i.li,{children:"Velocity space planning"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Local navigation strategies"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Khatib, O. (1986). "Real-time obstacle avoidance for manipulators and mobile robots." International Journal of Robotics Research.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Artificial potential field methods"}),"\n",(0,s.jsx)(i.li,{children:"Navigation functions"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Obstacle avoidance fundamentals"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"nvidia-isaac-navigation-integration",children:"NVIDIA Isaac Navigation Integration"}),"\n",(0,s.jsxs)(i.ol,{start:"13",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "Isaac ROS Navigation Integration." NVIDIA Developer Documentation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Isaac hardware acceleration"}),"\n",(0,s.jsx)(i.li,{children:"Integration with Nav2"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Isaac-Nav2 integration"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "Isaac ROS Navigation Package Documentation."'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"CUDA-accelerated navigation"}),"\n",(0,s.jsx)(i.li,{children:"Perception-integrated navigation"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Isaac-specific navigation packages"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "Isaac Sim Navigation Simulation."'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Navigation behavior validation"}),"\n",(0,s.jsx)(i.li,{children:"Performance evaluation in simulation"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Navigation validation in Isaac Sim"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"cross-chapter-integration-sources",children:"Cross-Chapter Integration Sources"}),"\n",(0,s.jsx)(i.h3,{id:"unity-isaac-integration",children:"Unity-Isaac Integration"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'NVIDIA. (2025). "Unity-Isaac Integration Guide." NVIDIA Developer Documentation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Mixed simulation environments"}),"\n",(0,s.jsx)(i.li,{children:"Data exchange between platforms"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Cross-platform simulation integration"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Unity Technologies & NVIDIA. (2025). "Simulation Interoperability Standards." Joint Technical Paper.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Format compatibility for simulation"}),"\n",(0,s.jsx)(i.li,{children:"Asset exchange between platforms"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Simulation interoperability"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"perception-navigation-integration",children:"Perception-Navigation Integration"}),"\n",(0,s.jsxs)(i.ol,{start:"3",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Thrun, S., et al. (2006). "Probabilistic Robotics." MIT Press.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:'Chapter 4: "Robot Motion"'}),"\n",(0,s.jsx)(i.li,{children:'Chapter 5: "Robot Perception"'}),"\n",(0,s.jsx)(i.li,{children:'Chapter 6: "Bayesian Filters"'}),"\n",(0,s.jsx)(i.li,{children:"Focus: Integration of perception and navigation"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Konolige, K., et al. (2010). "View-based loop closure for visual SLAM." RSS Workshop on Visual Place Recognition in Changing Environments.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Integration of SLAM with navigation"}),"\n",(0,s.jsx)(i.li,{children:"Map-based navigation approaches"}),"\n",(0,s.jsx)(i.li,{children:"Focus: SLAM-navigation integration"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"simulation-to-reality-transfer",children:"Simulation-to-Reality Transfer"}),"\n",(0,s.jsxs)(i.ol,{start:"5",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Sadeghi, A., & Levine, S. (2017). "CAD2RL: Real single-image flight without a single real image." arXiv preprint arXiv:1611.04208.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Domain randomization techniques"}),"\n",(0,s.jsx)(i.li,{children:"Reality gap mitigation"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Simulation-to-reality transfer"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Tobin, J., et al. (2017). "Domain randomization for transferring deep neural networks from simulation to the real world." IEEE/RSJ International Conference on Intelligent Robots and Systems.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Domain randomization for perception"}),"\n",(0,s.jsx)(i.li,{children:"Transfer learning techniques"}),"\n",(0,s.jsx)(i.li,{children:"Focus: Perception transfer from simulation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"academic-and-technical-validation-sources",children:"Academic and Technical Validation Sources"}),"\n",(0,s.jsx)(i.h3,{id:"performance-and-evaluation",children:"Performance and Evaluation"}),"\n",(0,s.jsxs)(i.ol,{children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'St\xfcckler, J., & Behnke, S. (2012). "Multi-resolution surfel mapping and real-time pose tracking." IEEE International Conference on Robotics and Automation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: Performance evaluation metrics"}),"\n",(0,s.jsx)(i.li,{children:"Application: Simulation performance assessment"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Endres, F., et al. (2012). "An evaluation of the RGB-D SLAM system." IEEE International Conference on Robotics and Automation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: SLAM evaluation frameworks"}),"\n",(0,s.jsx)(i.li,{children:"Application: Perception system validation"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'Brock, O., & Khatib, O. (1999). "High-speed navigation using the global dynamic window approach." IEEE International Conference on Robotics and Automation.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: Navigation performance evaluation"}),"\n",(0,s.jsx)(i.li,{children:"Application: Navigation system validation"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"standards-and-best-practices",children:"Standards and Best Practices"}),"\n",(0,s.jsxs)(i.ol,{start:"4",children:["\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:'ISO 18646-1:2015. "Service robots - Performance classification for navigation." International Organization for Standardization.'})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: Navigation performance standards"}),"\n",(0,s.jsx)(i.li,{children:"Application: Evaluation methodology standards"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(i.li,{children:["\n",(0,s.jsx)(i.p,{children:(0,s.jsx)(i.strong,{children:"IEEE Standard for Robot Map Data Representation for Navigation (IEEE 1873-2015)."})}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Focus: Map representation standards"}),"\n",(0,s.jsx)(i.li,{children:"Application: Navigation system standards"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"source-prioritization-by-chapter-focus",children:"Source Prioritization by Chapter Focus"}),"\n",(0,s.jsx)(i.h3,{id:"chapter-7-priorities-unity-integration",children:"Chapter 7 Priorities (Unity Integration)"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Unity Robotics Hub Documentation - Primary resource"}),"\n",(0,s.jsx)(i.li,{children:"Unity-ROS-TCP-Connector - Core integration tool"}),"\n",(0,s.jsx)(i.li,{children:"NVIDIA Unity-Isaac Guide - Cross-platform integration"}),"\n",(0,s.jsx)(i.li,{children:"Unity ML-Agents Toolkit - AI training in Unity"}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"chapter-8-priorities-isaac-sim",children:"Chapter 8 Priorities (Isaac Sim)"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"NVIDIA Isaac Sim Documentation - Primary resource"}),"\n",(0,s.jsx)(i.li,{children:"Isaac Gym Technical Paper - Technical foundation"}),"\n",(0,s.jsx)(i.li,{children:"Isaac ROS Integration Guide - ROS integration"}),"\n",(0,s.jsx)(i.li,{children:"Makoviychuk et al. (2021) - Technical architecture"}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"chapter-9-priorities-vslam",children:"Chapter 9 Priorities (VSLAM)"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Mur-Artal & Tardos (2017) - State-of-the-art SLAM"}),"\n",(0,s.jsx)(i.li,{children:"NVIDIA Isaac ROS VSLAM - ROS integration"}),"\n",(0,s.jsx)(i.li,{children:"Geiger et al. (2012) - Evaluation framework"}),"\n",(0,s.jsx)(i.li,{children:"Forster et al. (2017) - Visual-inertial fusion"}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"chapter-10-priorities-nav2",children:"Chapter 10 Priorities (Nav2)"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Navigation2 Documentation - Primary resource"}),"\n",(0,s.jsx)(i.li,{children:"Macenski et al. (2021) - Architecture overview"}),"\n",(0,s.jsx)(i.li,{children:"Colledanchise & \xd6gren (2018) - Behavior trees"}),"\n",(0,s.jsx)(i.li,{children:"Choset et al. (2005) - Path planning fundamentals"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"academic-credibility-assessment",children:"Academic Credibility Assessment"}),"\n",(0,s.jsx)(i.h3,{id:"highly-credible-sources-mit-press-springer-ieee",children:"Highly Credible Sources (MIT Press, Springer, IEEE)"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Thrun, Burgard & Fox (2006) - Probabilistic robotics standard"}),"\n",(0,s.jsx)(i.li,{children:"Choset et al. (2005) - Motion planning standard"}),"\n",(0,s.jsx)(i.li,{children:"Siegwart et al. (2011) - Mobile robotics standard"}),"\n",(0,s.jsx)(i.li,{children:"Colledanchise & \xd6gren (2018) - Behavior trees standard"}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"peer-reviewed-journal-papers-high-impact",children:"Peer-Reviewed Journal Papers (High Impact)"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Mur-Artal & Tardos (2017) - ORB-SLAM2 (5000+ citations)"}),"\n",(0,s.jsx)(i.li,{children:"Makoviychuk et al. (2021) - Isaac Gym (AI/Robotics)"}),"\n",(0,s.jsx)(i.li,{children:"Fox et al. (1997) - Dynamic Window (Robots)"}),"\n",(0,s.jsx)(i.li,{children:"Khatib (1986) - Potential Fields (Fundamental)"}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"industry-standard-documentation",children:"Industry-Standard Documentation"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"NVIDIA Isaac Documentation - Primary reference"}),"\n",(0,s.jsx)(i.li,{children:"ROS 2 Navigation Documentation - Standard reference"}),"\n",(0,s.jsx)(i.li,{children:"Unity Robotics Documentation - Official guide"}),"\n",(0,s.jsx)(i.li,{children:"Validated by community use and testing"}),"\n"]}),"\n",(0,s.jsx)(i.h2,{id:"relevance-to-target-audience",children:"Relevance to Target Audience"}),"\n",(0,s.jsx)(i.h3,{id:"graduate-student-level",children:"Graduate Student Level"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Appropriate balance of theory and implementation"}),"\n",(0,s.jsx)(i.li,{children:"Clear learning objectives and outcomes"}),"\n",(0,s.jsx)(i.li,{children:"Implementation examples and exercises"}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"implementation-oriented",children:"Implementation-Oriented"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Sources provide both theory and practical examples"}),"\n",(0,s.jsx)(i.li,{children:"Real-world applications and case studies"}),"\n",(0,s.jsx)(i.li,{children:"Open-source tools and frameworks"}),"\n"]}),"\n",(0,s.jsx)(i.h3,{id:"robotics-focused",children:"Robotics-Focused"}),"\n",(0,s.jsxs)(i.ul,{children:["\n",(0,s.jsx)(i.li,{children:"Sources specifically address robotic applications"}),"\n",(0,s.jsx)(i.li,{children:"Emphasis on embodied systems and real-time performance"}),"\n",(0,s.jsx)(i.li,{children:"Integration of perception, navigation, and intelligence"}),"\n"]}),"\n",(0,s.jsx)(i.hr,{}),"\n",(0,s.jsxs)(i.p,{children:[(0,s.jsx)(i.strong,{children:"Next Task"}),": Task 2.6 - Synthesize Chapter 7\u201310 Key Points"]})]})}function h(n={}){const{wrapper:i}={...(0,a.R)(),...n.components};return i?(0,s.jsx)(i,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453:(n,i,e)=>{e.d(i,{R:()=>l,x:()=>t});var r=e(6540);const s={},a=r.createContext(s);function l(n){const i=r.useContext(a);return r.useMemo(function(){return"function"==typeof n?n(i):{...i,...n}},[i,n])}function t(n){let i;return i=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:l(n.components),r.createElement(a.Provider,{value:i},n.children)}}}]);