# SP. Module 4 â€“ Vision-Language-Action (VLA)

## Focus
- Integrating LLMs and Robotics

## Topics
- Voice-to-Action using OpenAI Whisper
- Cognitive Planning: converting natural language commands into ROS 2 actions
- Multi-modal perception: speech, vision, sensors

## Capstone Preview
- Autonomous Humanoid receives voice commands, plans a path, navigates obstacles, and manipulates objects
